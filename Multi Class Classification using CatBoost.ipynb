{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class Classification using CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user --upgrade catboost\n",
    "!pip install --user --upgrade ipywidgets\n",
    "!pip install shap\n",
    "!pip install sklearn\n",
    "!pip install --upgrade numpy\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "print(catboost.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import requests\n",
    "#import json\n",
    "import re\n",
    "from io import StringIO\n",
    "from string import digits\n",
    "import itertools\n",
    "import os\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(\"<<your path and input excel file name with extension>>\")\n",
    "df = pd.read_csv(fname, sep=',', delimiter=None, header='infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print all the columns. This method helps wen the list of columns is large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(a) for a in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive the label column based on valuesin the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = under booking, 1 = No over or under booking, 2 = over booking\n",
    "def create_label(row):\n",
    "    if pd.isna(row['BOOKED_QUANTITY']) or pd.isna(row['BOOKED_VOLUME']):\n",
    "        val = 0\n",
    "    elif pd.isna(row['ACTUAL_QUANTITY']) or pd.isna(row['ACTUAL_VOLUME']):\n",
    "        val = 2\n",
    "    elif row['BOOKED_QUANTITY'] > row['ACTUAL_QUANTITY'] or row['BOOKED_VOLUME'] > row['ACTUAL_VOLUME']:\n",
    "        val = 2\n",
    "    elif row['BOOKED_QUANTITY'] < row['ACTUAL_QUANTITY'] or row['BOOKED_VOLUME'] < row['ACTUAL_VOLUME']:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df.apply(create_label, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the data is balanced. If it is not balanced, CatBoost has a way to handle the imbalance, as we will see during the model training process later in this script. Note that, as a best practice, the balancing needs to happen after the test data (hold out data) is separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive features such as year, month, day, day of the week, hour, minute, second, etc from the time stamp columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dateid_to_date(dateid):\n",
    "    return datetime.strptime(dateid, '%Y%m%d')\n",
    "\n",
    "def convert_timestampstr_to_date(timestamp):\n",
    "    if timestamp == 'nan' or '':\n",
    "        return ''\n",
    "    else:\n",
    "        return datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIMESTAMP'] = df['TIMESTAMP'].apply(str).apply(convert_timestampstr_to_date)\n",
    "df['TIMESTAMP_YEAR'] = df['TIMESTAMP'].dt.year\n",
    "df['TIMESTAMP_MONTH'] = df['TIMESTAMP'].dt.month\n",
    "df['TIMESTAMP_DAYOFTHEMONTH'] = df['TIMESTAMP'].dt.day\n",
    "df['TIMESTAMP_HOUR'] = df['TIMESTAMP'].dt.hour\n",
    "df['TIMESTAMP_MINUTE'] = df['TIMESTAMP'].dt.minute\n",
    "df['TIMESTAMP_SECOND'] = df['TIMESTAMP'].dt.second\n",
    "df['TIMESTAMP_WEEK'] = df['TIMESTAMP'].dt.isocalendar().week\n",
    "df['TIMESTAMP_WEEKDAY'] = df['TIMESTAMP'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns that are not useful for the training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID', 'ACTUAL_QUANTITY', 'ACTUAL_VOLUME', 'TIMESTAMP'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the non categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_CAT_COLS = ['BOOKED_QUANTITY', 'BOOKED_VOLUME'] # add other non categorical columns. Here, only a couple of columns are shown for the sake of illustration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest of the columns (except label) are categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COLS = [col for col in df.columns if col not in NON_CAT_COLS and col != 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(x) for x in CAT_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into categorical and non-categorical. This is required as all the categorical features need to be converted into string as per the requirements of CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cat = df[NON_CAT_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df[CAT_COLS + ['label']].astype(str).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Categorical Features: 113\n",
      "#Non Categorical Features: 51\n",
      "Total #Features: 164\n"
     ]
    }
   ],
   "source": [
    "print(\"#Categorical Features: \" + str(df_cat.shape[1] - 1))\n",
    "print(\"#Non Categorical Features: \" + str(df_non_cat.shape[1]))\n",
    "print(\"Total #Features: \" + str(df_cat.shape[1] + df_non_cat.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free up some of the pandas dataframes that are no needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del [[df, df_join, df_non_cat, df_cat]]\n",
    "gc.collect()\n",
    "df_chart1=pd.DataFrame()\n",
    "df_chart2=pd.DataFrame()\n",
    "df_chart3=pd.DataFrame()\n",
    "df_chart4=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the categorical and non-categorical features into X and separate the labels into y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cat.join(df_non_cat)\n",
    "y = X.label\n",
    "X = X.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training/validation and test datasets \n",
    "X_train_validation, X_test, y_train_validation, y_test = model_selection.train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_validation.head()\n",
    "# y_train_validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the data is balanced now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_validation.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "# X_train, X_validation, y_train, y_validation = model_selection.train_test_split(X_train_validation_ov, y_train_validation_ov, stratify=y_train_validation_ov)\n",
    "X_train, X_validation, y_train, y_validation = model_selection.train_test_split(X_train_validation, y_train_validation, stratify=y_train_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit the CatBoost model for multi-class classification. The number of iterations here is 100, but can be set to whatever is appropriate in a given scenario. The class weights are important as CatBoost uses them to handle the unbalanced data.\n",
    "\n",
    "## The weights are calculated by first dividing the number of records per class in the training data set by the total number of records in the training data set. Then subtract each value from 1 to arrive at the weights for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28d06c5aaf243deb39796d7d23fd2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.293503\n",
      "0:\tlearn: 0.8953525\ttest: 0.8943565\tbest: 0.8943565 (0)\ttotal: 25.5s\tremaining: 42m 7s\n",
      "1:\tlearn: 0.7932036\ttest: 0.7915256\tbest: 0.7915256 (1)\ttotal: 48.9s\tremaining: 39m 54s\n",
      "2:\tlearn: 0.7137698\ttest: 0.7121791\tbest: 0.7121791 (2)\ttotal: 1m 11s\tremaining: 38m 30s\n",
      "3:\tlearn: 0.6617851\ttest: 0.6616413\tbest: 0.6616413 (3)\ttotal: 1m 28s\tremaining: 35m 22s\n",
      "4:\tlearn: 0.6311685\ttest: 0.6315308\tbest: 0.6315308 (4)\ttotal: 1m 43s\tremaining: 32m 55s\n",
      "5:\tlearn: 0.6014221\ttest: 0.6009598\tbest: 0.6009598 (5)\ttotal: 2m 1s\tremaining: 31m 41s\n",
      "6:\tlearn: 0.5620689\ttest: 0.5613036\tbest: 0.5613036 (6)\ttotal: 2m 18s\tremaining: 30m 44s\n",
      "7:\tlearn: 0.5461100\ttest: 0.5457544\tbest: 0.5457544 (7)\ttotal: 2m 34s\tremaining: 29m 35s\n",
      "8:\tlearn: 0.5335934\ttest: 0.5325835\tbest: 0.5325835 (8)\ttotal: 2m 52s\tremaining: 29m 2s\n",
      "9:\tlearn: 0.5229896\ttest: 0.5219737\tbest: 0.5219737 (9)\ttotal: 3m 10s\tremaining: 28m 38s\n",
      "10:\tlearn: 0.5154749\ttest: 0.5145894\tbest: 0.5145894 (10)\ttotal: 3m 31s\tremaining: 28m 33s\n",
      "11:\tlearn: 0.4919677\ttest: 0.4910109\tbest: 0.4910109 (11)\ttotal: 3m 52s\tremaining: 28m 24s\n",
      "12:\tlearn: 0.4825699\ttest: 0.4814829\tbest: 0.4814829 (12)\ttotal: 4m 11s\tremaining: 28m 1s\n",
      "13:\tlearn: 0.4694066\ttest: 0.4680564\tbest: 0.4680564 (13)\ttotal: 4m 29s\tremaining: 27m 37s\n",
      "14:\tlearn: 0.4631764\ttest: 0.4620350\tbest: 0.4620350 (14)\ttotal: 4m 45s\tremaining: 27m\n",
      "15:\tlearn: 0.4524484\ttest: 0.4516973\tbest: 0.4516973 (15)\ttotal: 5m 1s\tremaining: 26m 21s\n",
      "16:\tlearn: 0.4475303\ttest: 0.4469118\tbest: 0.4469118 (16)\ttotal: 5m 18s\tremaining: 25m 55s\n",
      "17:\tlearn: 0.4391887\ttest: 0.4387782\tbest: 0.4387782 (17)\ttotal: 5m 36s\tremaining: 25m 34s\n",
      "18:\tlearn: 0.4354738\ttest: 0.4354017\tbest: 0.4354017 (18)\ttotal: 5m 53s\tremaining: 25m 7s\n",
      "19:\tlearn: 0.4292794\ttest: 0.4297766\tbest: 0.4297766 (19)\ttotal: 6m 12s\tremaining: 24m 51s\n",
      "20:\tlearn: 0.4210739\ttest: 0.4215891\tbest: 0.4215891 (20)\ttotal: 6m 29s\tremaining: 24m 25s\n",
      "21:\tlearn: 0.4128384\ttest: 0.4135767\tbest: 0.4135767 (21)\ttotal: 6m 46s\tremaining: 24m 1s\n",
      "22:\tlearn: 0.4073575\ttest: 0.4085225\tbest: 0.4085225 (22)\ttotal: 7m 2s\tremaining: 23m 33s\n",
      "23:\tlearn: 0.4030528\ttest: 0.4043939\tbest: 0.4043939 (23)\ttotal: 7m 16s\tremaining: 23m 3s\n",
      "24:\tlearn: 0.3998766\ttest: 0.4014842\tbest: 0.4014842 (24)\ttotal: 7m 33s\tremaining: 22m 39s\n",
      "25:\tlearn: 0.3973977\ttest: 0.3990781\tbest: 0.3990781 (25)\ttotal: 7m 51s\tremaining: 22m 23s\n",
      "26:\tlearn: 0.3937973\ttest: 0.3959883\tbest: 0.3959883 (26)\ttotal: 8m 10s\tremaining: 22m 6s\n",
      "27:\tlearn: 0.3913119\ttest: 0.3933541\tbest: 0.3933541 (27)\ttotal: 8m 26s\tremaining: 21m 42s\n",
      "28:\tlearn: 0.3881175\ttest: 0.3904943\tbest: 0.3904943 (28)\ttotal: 8m 45s\tremaining: 21m 26s\n",
      "29:\tlearn: 0.3779877\ttest: 0.3804316\tbest: 0.3804316 (29)\ttotal: 9m 2s\tremaining: 21m 5s\n",
      "30:\tlearn: 0.3728068\ttest: 0.3750056\tbest: 0.3750056 (30)\ttotal: 9m 21s\tremaining: 20m 49s\n",
      "31:\tlearn: 0.3694936\ttest: 0.3721204\tbest: 0.3721204 (31)\ttotal: 9m 37s\tremaining: 20m 26s\n",
      "32:\tlearn: 0.3676048\ttest: 0.3707127\tbest: 0.3707127 (32)\ttotal: 9m 52s\tremaining: 20m 3s\n",
      "33:\tlearn: 0.3653348\ttest: 0.3683662\tbest: 0.3683662 (33)\ttotal: 10m 11s\tremaining: 19m 47s\n",
      "34:\tlearn: 0.3606603\ttest: 0.3637363\tbest: 0.3637363 (34)\ttotal: 10m 30s\tremaining: 19m 30s\n",
      "35:\tlearn: 0.3583113\ttest: 0.3617497\tbest: 0.3617497 (35)\ttotal: 10m 47s\tremaining: 19m 11s\n",
      "36:\tlearn: 0.3567137\ttest: 0.3601582\tbest: 0.3601582 (36)\ttotal: 11m 4s\tremaining: 18m 51s\n",
      "37:\tlearn: 0.3526938\ttest: 0.3561410\tbest: 0.3561410 (37)\ttotal: 11m 21s\tremaining: 18m 31s\n",
      "38:\tlearn: 0.3511745\ttest: 0.3547477\tbest: 0.3547477 (38)\ttotal: 11m 37s\tremaining: 18m 11s\n",
      "39:\tlearn: 0.3469424\ttest: 0.3507213\tbest: 0.3507213 (39)\ttotal: 11m 52s\tremaining: 17m 48s\n",
      "40:\tlearn: 0.3422535\ttest: 0.3457499\tbest: 0.3457499 (40)\ttotal: 12m 11s\tremaining: 17m 33s\n",
      "41:\tlearn: 0.3410704\ttest: 0.3450586\tbest: 0.3450586 (41)\ttotal: 12m 27s\tremaining: 17m 12s\n",
      "42:\tlearn: 0.3377732\ttest: 0.3419925\tbest: 0.3419925 (42)\ttotal: 12m 43s\tremaining: 16m 51s\n",
      "43:\tlearn: 0.3358971\ttest: 0.3401794\tbest: 0.3401794 (43)\ttotal: 12m 59s\tremaining: 16m 32s\n",
      "44:\tlearn: 0.3322679\ttest: 0.3367451\tbest: 0.3367451 (44)\ttotal: 13m 16s\tremaining: 16m 13s\n",
      "45:\tlearn: 0.3304745\ttest: 0.3352505\tbest: 0.3352505 (45)\ttotal: 13m 34s\tremaining: 15m 55s\n",
      "46:\tlearn: 0.3280390\ttest: 0.3327535\tbest: 0.3327535 (46)\ttotal: 13m 50s\tremaining: 15m 36s\n",
      "47:\tlearn: 0.3268238\ttest: 0.3317329\tbest: 0.3317329 (47)\ttotal: 14m 8s\tremaining: 15m 19s\n",
      "48:\tlearn: 0.3250973\ttest: 0.3301716\tbest: 0.3301716 (48)\ttotal: 14m 23s\tremaining: 14m 59s\n",
      "49:\tlearn: 0.3215881\ttest: 0.3265768\tbest: 0.3265768 (49)\ttotal: 14m 39s\tremaining: 14m 39s\n",
      "50:\tlearn: 0.3206979\ttest: 0.3257703\tbest: 0.3257703 (50)\ttotal: 14m 56s\tremaining: 14m 21s\n",
      "51:\tlearn: 0.3197863\ttest: 0.3251112\tbest: 0.3251112 (51)\ttotal: 15m 12s\tremaining: 14m 1s\n",
      "52:\tlearn: 0.3177242\ttest: 0.3227756\tbest: 0.3227756 (52)\ttotal: 15m 31s\tremaining: 13m 45s\n",
      "53:\tlearn: 0.3170728\ttest: 0.3223364\tbest: 0.3223364 (53)\ttotal: 15m 47s\tremaining: 13m 27s\n",
      "54:\tlearn: 0.3165361\ttest: 0.3221270\tbest: 0.3221270 (54)\ttotal: 16m 6s\tremaining: 13m 11s\n",
      "55:\tlearn: 0.3158446\ttest: 0.3216054\tbest: 0.3216054 (55)\ttotal: 16m 24s\tremaining: 12m 53s\n",
      "56:\tlearn: 0.3150393\ttest: 0.3208782\tbest: 0.3208782 (56)\ttotal: 16m 39s\tremaining: 12m 34s\n",
      "57:\tlearn: 0.3137318\ttest: 0.3198159\tbest: 0.3198159 (57)\ttotal: 16m 55s\tremaining: 12m 15s\n",
      "58:\tlearn: 0.3119717\ttest: 0.3180422\tbest: 0.3180422 (58)\ttotal: 17m 10s\tremaining: 11m 56s\n",
      "59:\tlearn: 0.3115807\ttest: 0.3178030\tbest: 0.3178030 (59)\ttotal: 17m 25s\tremaining: 11m 37s\n",
      "60:\tlearn: 0.3103821\ttest: 0.3169365\tbest: 0.3169365 (60)\ttotal: 17m 42s\tremaining: 11m 19s\n",
      "61:\tlearn: 0.3088641\ttest: 0.3154727\tbest: 0.3154727 (61)\ttotal: 18m\tremaining: 11m 2s\n",
      "62:\tlearn: 0.3084174\ttest: 0.3152919\tbest: 0.3152919 (62)\ttotal: 18m 16s\tremaining: 10m 43s\n",
      "63:\tlearn: 0.3063884\ttest: 0.3131703\tbest: 0.3131703 (63)\ttotal: 18m 32s\tremaining: 10m 25s\n",
      "64:\tlearn: 0.3051637\ttest: 0.3119916\tbest: 0.3119916 (64)\ttotal: 18m 48s\tremaining: 10m 7s\n",
      "65:\tlearn: 0.3049117\ttest: 0.3119164\tbest: 0.3119164 (65)\ttotal: 19m 3s\tremaining: 9m 49s\n",
      "66:\tlearn: 0.3034619\ttest: 0.3108056\tbest: 0.3108056 (66)\ttotal: 19m 19s\tremaining: 9m 31s\n",
      "67:\tlearn: 0.3025746\ttest: 0.3100004\tbest: 0.3100004 (67)\ttotal: 19m 35s\tremaining: 9m 13s\n",
      "68:\tlearn: 0.3009889\ttest: 0.3083861\tbest: 0.3083861 (68)\ttotal: 19m 50s\tremaining: 8m 55s\n",
      "69:\tlearn: 0.2989193\ttest: 0.3064147\tbest: 0.3064147 (69)\ttotal: 20m 8s\tremaining: 8m 37s\n",
      "70:\tlearn: 0.2978651\ttest: 0.3056537\tbest: 0.3056537 (70)\ttotal: 20m 25s\tremaining: 8m 20s\n",
      "71:\tlearn: 0.2978128\ttest: 0.3056234\tbest: 0.3056234 (71)\ttotal: 20m 41s\tremaining: 8m 2s\n",
      "72:\tlearn: 0.2971729\ttest: 0.3055405\tbest: 0.3055405 (72)\ttotal: 20m 57s\tremaining: 7m 45s\n",
      "73:\tlearn: 0.2964333\ttest: 0.3051138\tbest: 0.3051138 (73)\ttotal: 21m 17s\tremaining: 7m 28s\n",
      "74:\tlearn: 0.2962509\ttest: 0.3050796\tbest: 0.3050796 (74)\ttotal: 21m 35s\tremaining: 7m 11s\n",
      "75:\tlearn: 0.2960872\ttest: 0.3049973\tbest: 0.3049973 (75)\ttotal: 21m 51s\tremaining: 6m 54s\n",
      "76:\tlearn: 0.2959600\ttest: 0.3049303\tbest: 0.3049303 (76)\ttotal: 22m 8s\tremaining: 6m 36s\n",
      "77:\tlearn: 0.2952629\ttest: 0.3042488\tbest: 0.3042488 (77)\ttotal: 22m 25s\tremaining: 6m 19s\n",
      "78:\tlearn: 0.2951524\ttest: 0.3041761\tbest: 0.3041761 (78)\ttotal: 22m 42s\tremaining: 6m 2s\n",
      "79:\tlearn: 0.2946441\ttest: 0.3038299\tbest: 0.3038299 (79)\ttotal: 22m 58s\tremaining: 5m 44s\n",
      "80:\tlearn: 0.2944931\ttest: 0.3038054\tbest: 0.3038054 (80)\ttotal: 23m 14s\tremaining: 5m 27s\n",
      "81:\tlearn: 0.2942404\ttest: 0.3037603\tbest: 0.3037603 (81)\ttotal: 23m 29s\tremaining: 5m 9s\n",
      "82:\tlearn: 0.2941414\ttest: 0.3037279\tbest: 0.3037279 (82)\ttotal: 23m 45s\tremaining: 4m 51s\n",
      "83:\tlearn: 0.2933940\ttest: 0.3031345\tbest: 0.3031345 (83)\ttotal: 24m\tremaining: 4m 34s\n",
      "84:\tlearn: 0.2910864\ttest: 0.3007624\tbest: 0.3007624 (84)\ttotal: 24m 15s\tremaining: 4m 16s\n",
      "85:\tlearn: 0.2900536\ttest: 0.2998951\tbest: 0.2998951 (85)\ttotal: 24m 30s\tremaining: 3m 59s\n",
      "86:\tlearn: 0.2899317\ttest: 0.2998314\tbest: 0.2998314 (86)\ttotal: 24m 48s\tremaining: 3m 42s\n",
      "87:\tlearn: 0.2893853\ttest: 0.2993608\tbest: 0.2993608 (87)\ttotal: 25m 4s\tremaining: 3m 25s\n",
      "88:\tlearn: 0.2892029\ttest: 0.2992619\tbest: 0.2992619 (88)\ttotal: 25m 20s\tremaining: 3m 7s\n",
      "89:\tlearn: 0.2887650\ttest: 0.2987981\tbest: 0.2987981 (89)\ttotal: 25m 36s\tremaining: 2m 50s\n",
      "90:\tlearn: 0.2877253\ttest: 0.2978838\tbest: 0.2978838 (90)\ttotal: 25m 51s\tremaining: 2m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91:\tlearn: 0.2873832\ttest: 0.2975971\tbest: 0.2975971 (91)\ttotal: 26m 7s\tremaining: 2m 16s\n",
      "92:\tlearn: 0.2871506\ttest: 0.2975546\tbest: 0.2975546 (92)\ttotal: 26m 22s\tremaining: 1m 59s\n",
      "93:\tlearn: 0.2866048\ttest: 0.2973057\tbest: 0.2973057 (93)\ttotal: 26m 37s\tremaining: 1m 41s\n",
      "94:\tlearn: 0.2862997\ttest: 0.2971717\tbest: 0.2971717 (94)\ttotal: 26m 53s\tremaining: 1m 24s\n",
      "95:\tlearn: 0.2860989\ttest: 0.2970655\tbest: 0.2970655 (95)\ttotal: 27m 10s\tremaining: 1m 7s\n",
      "96:\tlearn: 0.2858406\ttest: 0.2969869\tbest: 0.2969869 (96)\ttotal: 27m 26s\tremaining: 50.9s\n",
      "97:\tlearn: 0.2856983\ttest: 0.2969519\tbest: 0.2969519 (97)\ttotal: 27m 42s\tremaining: 33.9s\n",
      "98:\tlearn: 0.2845121\ttest: 0.2958672\tbest: 0.2958672 (98)\ttotal: 27m 59s\tremaining: 17s\n",
      "99:\tlearn: 0.2843772\ttest: 0.2958216\tbest: 0.2958216 (99)\ttotal: 28m 16s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2958215783\n",
      "bestIteration = 99\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1d4f4f52c40>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    random_seed=43,\n",
    "    loss_function='MultiClass',\n",
    "    class_weights={0: 0.989352004, 1: 0.078047624, 2: 0.932600372}\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=CAT_COLS,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=True,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the feature importance (in this case I am filtering out the features that contribute less than 1% of predictivesignal). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = model.get_feature_importance(prettified=True)\n",
    "feature_imp[feature_imp['Importances'] > 1].sort_values(by=['Importances'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the outputs for the test data (hold out data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the y_test back to int as both y_test and predictions need to be of the same type to be compared to determine model performance. Note that y_test was converted to string along with all the other categorical columns earlier in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the classification model performance report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.42      0.41      1947\n",
      "           1       0.99      0.98      0.98    168552\n",
      "           2       0.81      0.90      0.85     12322\n",
      "\n",
      "    accuracy                           0.97    182821\n",
      "   macro avg       0.73      0.77      0.75    182821\n",
      "weighted avg       0.97      0.97      0.97    182821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report for test data')\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As you can see, the precision, recall and f1 scores for the output classes 1 and 2 are good, but the scores for the output class 0 is not that great. This could possibly be resolved by getting more samples for this minority class in the training and testing data or by engineering more that have greater predictive signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
